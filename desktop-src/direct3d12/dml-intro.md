---
title: Introduction à DirectML
description: Direct Machine Learning (DirectML) est une API de bas niveau pour Machine Learning (ML).
ms.custom: Windows 10 May 2019 Update
ms.localizationpriority: high
ms.topic: article
ms.date: 04/19/2019
ms.openlocfilehash: 2dd37bc4c27364e26e4bbd4ae2cf5d43031c3314
ms.sourcegitcommit: 2d531328b6ed82d4ad971a45a5131b430c5866f7
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 09/16/2019
ms.locfileid: "74104220"
---
# <a name="introduction-to-directml"></a><span data-ttu-id="ccf6c-103">Introduction à DirectML</span><span class="sxs-lookup"><span data-stu-id="ccf6c-103">Introduction to DirectML</span></span>

## <a name="summary"></a><span data-ttu-id="ccf6c-104">Résumé</span><span class="sxs-lookup"><span data-stu-id="ccf6c-104">Summary</span></span>

<span data-ttu-id="ccf6c-105">Direct Machine Learning (DirectML) est une API de bas niveau pour Machine Learning (ML).</span><span class="sxs-lookup"><span data-stu-id="ccf6c-105">Direct Machine Learning (DirectML) is a low-level API for machine learning (ML).</span></span> <span data-ttu-id="ccf6c-106">Les primitives Machine Learning accélérées par le matériel (appelés opérateurs) sont les blocs de construction de DirectML.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-106">Hardware-accelerated machine learning primitives (called operators) are the building blocks of DirectML.</span></span> <span data-ttu-id="ccf6c-107">À partir de ces blocs de construction, vous pouvez développer des techniques de Machine Learning telles que la mise à l’échelle, l’anticrénelage et le transfert de style, à un nom donné.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-107">From those building blocks, you can develop such machine learning techniques as upscaling, anti-aliasing, and style transfer, to name but a few.</span></span> <span data-ttu-id="ccf6c-108">Denoising et la Super-résolution, par exemple, vous permettent d’obtenir des effets raytraced impressionnants avec moins de rayons par pixel.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-108">Denoising and super-resolution, for example, allow you to achieve impressive raytraced effects with fewer rays per pixel.</span></span>

<span data-ttu-id="ccf6c-109">Vous pouvez intégrer l’apprentissage machine par le biais d’inférences de charges de travail dans votre jeu, votre moteur, votre intergiciel (middleware), votre serveur principal ou toute autre application.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-109">You can integrate machine learning inferencing workloads into your game, engine, middleware, backend, or other application.</span></span> <span data-ttu-id="ccf6c-110">DirectML dispose d’une interface de programmation de style et d’un flux de travail DirectX 12 familiers (C++ natif, nano-COM) et est prise en charge par tous les matériels compatibles DirectX 12.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-110">DirectML has a familiar (native C++, nano-COM) DirectX 12-style programming interface and workflow, and it's supported by all DirectX 12-compatible hardware.</span></span> <span data-ttu-id="ccf6c-111">Pour obtenir des exemples d’applications DirectML, y compris un exemple d’application DirectML minimale, consultez [exemples d’applications DirectML](dml-min-app.md).</span><span class="sxs-lookup"><span data-stu-id="ccf6c-111">For DirectML sample applications, including a sample of a minimal DirectML application, see [DirectML sample applications](dml-min-app.md).</span></span>

<span data-ttu-id="ccf6c-112">DirectML est introduit dans Windows 10, version 1903 et dans la version correspondante du SDK Windows.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-112">DirectML is introduced in Windows 10, version 1903, and in the corresponding version of the Windows SDK.</span></span>

## <a name="is-directml-appropriate-for-my-project"></a><span data-ttu-id="ccf6c-113">Le DirectML est-il adapté à mon projet ?</span><span class="sxs-lookup"><span data-stu-id="ccf6c-113">Is DirectML appropriate for my project?</span></span>

<span data-ttu-id="ccf6c-114">DirectML est un composant de l’parapluie [Windows machine learning](/windows/ai) .</span><span class="sxs-lookup"><span data-stu-id="ccf6c-114">DirectML is a component under the [Windows Machine Learning](/windows/ai) umbrella.</span></span> <span data-ttu-id="ccf6c-115">L’API WinML de niveau supérieur est principalement axée sur les modèles, avec son flux de travail de liaison de charge et d’évaluation.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-115">The higher-level WinML API is primarily model-focused, with its load-bind-evaluate workflow.</span></span> <span data-ttu-id="ccf6c-116">Toutefois, les domaines tels que les jeux et les moteurs nécessitent généralement un niveau d’abstraction inférieur et un degré de contrôle du développeur plus élevé, afin de tirer pleinement parti du silicium.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-116">But domains such as games and engines typically need a lower level of abstraction, and a higher degree of developer control, in order to take full advantage of the silicon.</span></span> <span data-ttu-id="ccf6c-117">Si vous comptez des millisecondes et des temps de compression, DirectML répond à vos besoins en matière de Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-117">If you're counting milliseconds, and squeezing frame times, then DirectML will meet your machine learning needs.</span></span>

<span data-ttu-id="ccf6c-118">Pour des scénarios fiables, en temps réel et à faible latence, et/ou à ressources restreintes, utilisez DirectML (plutôt que WinML).</span><span class="sxs-lookup"><span data-stu-id="ccf6c-118">For reliable real-time, high-performance, low-latency, and/or resource-constrained scenarios, use DirectML (rather than WinML).</span></span> <span data-ttu-id="ccf6c-119">Vous pouvez intégrer DirectML directement dans le moteur ou le pipeline de rendu existant.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-119">You can integrate DirectML directly into your existing engine or rendering pipeline.</span></span> <span data-ttu-id="ccf6c-120">Ou, à un niveau plus élevé pour les infrastructures d’Machine Learning personnalisées et les intergiciel, DirectML peut fournir un backend haute performance sur Windows.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-120">Or, at a higher level for custom machine learning frameworks and middleware, DirectML can provide a high-performance backend on Windows.</span></span>

<span data-ttu-id="ccf6c-121">WinML est lui-même implémenté à l’aide de DirectML comme l’un de ses serveurs principaux.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-121">WinML is itself implemented using DirectML as one of its backends.</span></span>

## <a name="what-work-does-directml-do-and-what-work-must-i-do-as-the-developer"></a><span data-ttu-id="ccf6c-122">Ce que fait DirectML le travail ; et quel travail dois- *je* faire en tant que développeur ?</span><span class="sxs-lookup"><span data-stu-id="ccf6c-122">What work does DirectML do; and what work must *I* do as the developer?</span></span>

<span data-ttu-id="ccf6c-123">DirectML exécute efficacement les couches individuelles de votre modèle d’inférence sur le GPU (ou sur les cœurs d’accélération AI, le cas échéant).</span><span class="sxs-lookup"><span data-stu-id="ccf6c-123">DirectML efficiently executes the individual layers of your inference model on the GPU (or on AI-acceleration cores, if present).</span></span> <span data-ttu-id="ccf6c-124">Chaque couche est un opérateur et DirectML vous fournit une bibliothèque d’opérateurs de niveau inférieur, accéléré par le matériel Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-124">Each layer is an operator, and DirectML provides you with a library of low-level, hardware-accelerated machine learning primitive operators.</span></span> <span data-ttu-id="ccf6c-125">Ces opérateurs ont des optimisations propres au matériel et à l’architecture, qui sont conçues pour eux ( [nous en ReDirectMLnt](#why-does-directml-perform-so-well)davantage dans la section pourquoi les performances sont-elles tellement bonnes ?).</span><span class="sxs-lookup"><span data-stu-id="ccf6c-125">These operators have hardware-specific and architecture-specific optimizations designed in to them (more on that in the section [Why does DirectML perform so well?](#why-does-directml-perform-so-well)).</span></span> <span data-ttu-id="ccf6c-126">En même temps, en tant que développeur, vous voyez une interface unique indépendante du fournisseur pour l’exécution de ces opérateurs.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-126">At the same time, you as the developer see a single, vendor-agnostic interface for executing those operators.</span></span>

<span data-ttu-id="ccf6c-127">La bibliothèque d’opérateurs dans DirectML fournit toutes les opérations habituelles que vous devriez pouvoir utiliser dans une charge de travail de Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-127">The library of operators in DirectML supplies all of the usual operations that you'd expect to be able to use in a machine learning workload.</span></span>

- <span data-ttu-id="ccf6c-128">Les opérateurs d’activation, tels que **Linear**, **ReLU**, **sigmoïde**, **Tanh**, etc.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-128">Activation operators, such as **linear**, **ReLU**, **sigmoid**, **tanh**, and more.</span></span>
- <span data-ttu-id="ccf6c-129">Les opérateurs basés sur les éléments, tels que **Add**, **exp**, **log**, **Max**, **min**, **Sub**, etc.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-129">Element-wise operators, such as **add**, **exp**, **log**, **max**, **min**, **sub**, and more.</span></span>
- <span data-ttu-id="ccf6c-130">Les opérateurs de convolution, tels que les **convolutions** 2D et 3D, etc.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-130">Convolution operators, such as 2D and 3D **convolution**, and more.</span></span>
- <span data-ttu-id="ccf6c-131">Les opérateurs de réduction, tels que **argmin**, **Average**, **L2**, **Sum**, etc.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-131">Reduction operators, such as **argmin**, **average**, **l2**, **sum**, and more.</span></span>
- <span data-ttu-id="ccf6c-132">Opérateurs de regroupement, tels que **Average**, **LP** et **Max**.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-132">Pooling operators, such as **average**, **lp**, and **max**.</span></span>
- <span data-ttu-id="ccf6c-133">Les opérateurs de réseau neuronal (NN), tels que **GEMM**, **Gru**, **LSTM** et **RNN**.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-133">Neural network (NN) operators, such as **gemm**, **gru**, **lstm**, and **rnn**.</span></span>
- <span data-ttu-id="ccf6c-134">Et bien plus encore.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-134">And many more.</span></span>

<span data-ttu-id="ccf6c-135">Pour des performances maximales, et afin de ne pas payer pour ce que vous n’utilisez pas, DirectML met le contrôle dans vos mains en tant que développeur sur la façon dont votre charge de travail Machine Learning est exécutée sur le matériel.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-135">For maximal performance, and so that you don't pay for what you don't use, DirectML puts the control into your hands as a developer over how your machine learning workload is executed on the hardware.</span></span> <span data-ttu-id="ccf6c-136">Il vous incombe de déterminer quels opérateurs exécuter et quand, est votre responsabilité en tant que développeur.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-136">Figuring out which operators to execute, and when, is your responsibility as the developer.</span></span> <span data-ttu-id="ccf6c-137">Les tâches qui sont laissées à votre discrétion incluent : la transcription du modèle ; simplification et optimisation de vos couches ; poids de chargement ; allocation des ressources, liaison, gestion de la mémoire (tout comme avec Direct3D 12); et l’exécution du graphique.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-137">Tasks that are left to your discretion include: transcribing the model; simplifying and optimizing your layers; loading weights; resource allocation, binding, memory management (just as with Direct3D 12); and execution of the graph.</span></span>

<span data-ttu-id="ccf6c-138">Vous conservez des connaissances de haut niveau de vos graphiques (vous pouvez coder en dur votre modèle directement, ou vous pouvez écrire votre propre chargeur de modèle).</span><span class="sxs-lookup"><span data-stu-id="ccf6c-138">You retain high-level knowledge of your graphs (you can hard-code your model directly, or you can write your own model loader).</span></span> <span data-ttu-id="ccf6c-139">Vous pouvez concevoir un **modèle de mise** à l’échelle, par exemple en utilisant plusieurs couches, chacune d’entre elles, les opérateurs de **convolution**, de **normalisation** et d' **activation** .</span><span class="sxs-lookup"><span data-stu-id="ccf6c-139">You might design an upscaling model, for example, using several layers each of **upsample**, **convolution**, **normalization**, and **activation** operators.</span></span> <span data-ttu-id="ccf6c-140">Grâce à cette connaissance, à la planification soignée et à la gestion des barrières, vous pouvez extraire le plus de parallélisme et les performances du matériel.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-140">With that familiarity, careful scheduling, and barrier management, you can extract the most parallelism and performance from the hardware.</span></span> <span data-ttu-id="ccf6c-141">Si vous développez un jeu, votre gestion des ressources minutieuse et le contrôle de la planification vous permettent d’entrelacer Machine Learning charges de travail et le travail de rendu traditionnel afin de saturer le GPU.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-141">If you're developing a game, then your careful resource management and control over scheduling enables you to interleave machine learning workloads and traditional rendering work in order to saturate the GPU.</span></span>

## <a name="whats-the-high-level-directml-workflow"></a><span data-ttu-id="ccf6c-142">Qu’est-ce que le flux de travail DirectML de haut niveau ?</span><span class="sxs-lookup"><span data-stu-id="ccf6c-142">What's the high-level DirectML workflow?</span></span>

<span data-ttu-id="ccf6c-143">Voici la recette de haut niveau de la façon dont nous pensons que les DirectML sont utilisés.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-143">Here's the high-level recipe for how we expect DirectML to be used.</span></span> <span data-ttu-id="ccf6c-144">Dans les deux phases principales de l’initialisation et de l’exécution, vous enregistrez votre travail dans des listes de commandes, puis vous les exécutez dans une file d’attente.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-144">Within the two main phases of initialization and execution, you record work into command lists and then you execute them on a queue.</span></span>

### <a name="initialization"></a><span data-ttu-id="ccf6c-145">Initialisation</span><span class="sxs-lookup"><span data-stu-id="ccf6c-145">Initialization</span></span>

1. <span data-ttu-id="ccf6c-146">Créez vos ressources Direct3D 12 sur &mdash; le périphérique Direct3D 12, la file d’attente de commandes, la liste des commandes et les ressources telles que les tas de descripteurs.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-146">Create your Direct3D 12 resources&mdash;the Direct3D 12 device, command queue, command list, and resources such as descriptor heaps.</span></span>
2. <span data-ttu-id="ccf6c-147">Étant donné que vous effectuez Machine Learning inférence, ainsi que votre charge de travail de rendu, créez des ressources DirectML &mdash; les instances de l’appareil DirectML et de l’opérateur.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-147">Since you're doing machine learning inferencing as well as your rendering workload, create DirectML resources&mdash;the DirectML device, and operator instances.</span></span> <span data-ttu-id="ccf6c-148">Si vous avez un modèle de Machine Learning dans lequel vous devez effectuer un type particulier de convolution avec une taille particulière de tenseur de filtre avec un type de données particulier, alors il s’agit de tous les paramètres de l’opérateur de **convolution** de DirectML.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-148">If you have a machine learning model where you need to perform a particular type of convolution with a particular size of filter tensor with a particular data type, then those are all parameters into DirectML's **convolution** operator.</span></span>
3. <span data-ttu-id="ccf6c-149">Les enregistrements DirectML fonctionnent dans les listes de commandes Direct3D 12.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-149">DirectML records work into Direct3D 12 command lists.</span></span> <span data-ttu-id="ccf6c-150">Ainsi, une fois l’initialisation terminée, vous enregistrez la liaison et l’initialisation de (par exemple) votre opérateur de convolution dans votre liste de commandes.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-150">So, once initialization is done, you record the binding and initialization of (for example) your convolution operator into your command list.</span></span> <span data-ttu-id="ccf6c-151">Ensuite, fermez et exécutez votre liste de commandes dans votre file d’attente comme d’habitude.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-151">Then, close and execute your command list on your queue as usual.</span></span>

### <a name="execution"></a><span data-ttu-id="ccf6c-152">Exécution</span><span class="sxs-lookup"><span data-stu-id="ccf6c-152">Execution</span></span>

1. <span data-ttu-id="ccf6c-153">Chargez vos plus de dizaines de poids dans les ressources.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-153">Upload your weight tensors into resources.</span></span> <span data-ttu-id="ccf6c-154">Un tenseur dans DirectML est représenté à l’aide d’une ressource Direct3D 12 standard.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-154">A tensor in DirectML is represented using a regular Direct3D 12 resource.</span></span> <span data-ttu-id="ccf6c-155">Par exemple, si vous souhaitez télécharger vos données de poids vers le GPU, vous procédez de la même façon que vous le feriez avec n’importe quelle autre ressource Direct3D 12 (utilisez un segment de mémoire de chargement ou la file d’attente de copie).</span><span class="sxs-lookup"><span data-stu-id="ccf6c-155">For example, if you want to upload your weight data to the GPU, then you do that the same way you would with any other Direct3D 12 resource (use an upload heap, or the copy queue).</span></span>
2. <span data-ttu-id="ccf6c-156">Ensuite, vous devez lier ces ressources Direct3D 12 comme des dizaines d’entrée et de sortie.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-156">Next, you need to bind those Direct3D 12 resources as your input and output tensors.</span></span> <span data-ttu-id="ccf6c-157">Enregistrement dans votre commande répertorie la liaison et l’exécution de vos opérateurs.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-157">Record into your command list the binding and the execution of your operators.</span></span>
3. <span data-ttu-id="ccf6c-158">Fermez et exécutez votre liste de commandes.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-158">Close and execute your command list.</span></span>

<span data-ttu-id="ccf6c-159">Tout comme avec Direct3D 12, vous êtes responsable de la durée de vie des ressources et de la synchronisation.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-159">Just as with Direct3D 12, resource lifetime and synchronization are your responsibility.</span></span> <span data-ttu-id="ccf6c-160">Par exemple, ne libérez pas vos objets DirectML au moins jusqu’à ce qu’ils aient terminé leur exécution sur le GPU.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-160">For example, don't release your DirectML objects at least until they've completed execution on the GPU.</span></span>

## <a name="why-does-directml-perform-so-well"></a><span data-ttu-id="ccf6c-161">Pourquoi DirectML fonctionne-t-il bien ?</span><span class="sxs-lookup"><span data-stu-id="ccf6c-161">Why does DirectML perform so well?</span></span>

<span data-ttu-id="ccf6c-162">Il y a une bonne raison pour laquelle vous ne devriez pas simplement écrire votre propre opérateur de convolution (par exemple) en langage HLSL dans un [nuanceur de calcul](/windows/desktop/direct3d12/pipelines-and-shaders-with-directx-12#direct3d-12-compute-pipeline).</span><span class="sxs-lookup"><span data-stu-id="ccf6c-162">There's a good reason why you shouldn't just write your own convolution operator (for example) as HLSL in a [compute shader](/windows/desktop/direct3d12/pipelines-and-shaders-with-directx-12#direct3d-12-compute-pipeline).</span></span> <span data-ttu-id="ccf6c-163">L’avantage de l’utilisation de DirectML est que, en &mdash; dehors de l’économie de l’effort de Homebrewing votre propre solution &mdash; , elle permet de fournir des performances nettement supérieures à celles d’un nuanceur de calcul manuel écrit et à usage général pour une telle **convolution** ou **LSTM**.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-163">The advantage of using DirectML is that&mdash;apart from saving you the effort of homebrewing your own solution&mdash;it has the capability of giving you much better performance than you could achieve with a hand-written, general-purpose compute shader for something like **convolution**, or **lstm**.</span></span>

<span data-ttu-id="ccf6c-164">DirectML réalise cela en partie en raison de la fonctionnalité de recommandes Direct3D 12.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-164">DirectML achieves this in part due to the Direct3D 12 metacommands feature.</span></span> <span data-ttu-id="ccf6c-165">Les recommandes exposent une boîte noire des fonctionnalités jusqu’à DirectML, ce qui permet aux fournisseurs de matériel de fournir un accès DirectML aux optimisations spécifiques au matériel et à l’architecture du fournisseur.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-165">Metacommands expose a black box of functionality up to DirectML, which allows hardware vendors to provide DirectML access to vendor hardware-specific and architecture-specific optimizations.</span></span> <span data-ttu-id="ccf6c-166">Plusieurs opérateurs &mdash; , par exemple, la convolution suivie par l’activation &mdash; peut être regroupé en une seule recommande. </span><span class="sxs-lookup"><span data-stu-id="ccf6c-166">Multiple operators&mdash;for example, convolution followed by activation&mdash;can be *fused* together into a single metacommand.</span></span> <span data-ttu-id="ccf6c-167">En raison de ces facteurs, DirectML a la possibilité de dépasser les performances d’un nuanceur de calcul à la main, bien écrit et écrit pour s’exécuter sur une large gamme de matériel.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-167">Because of these factors, DirectML has the capability to exceed the performance of even a very well-written hand-tuned compute shader written to run on a breadth of hardware.</span></span>

<span data-ttu-id="ccf6c-168">Les recommandes font partie de l’API Direct3D 12, bien qu’elles soient faiblement couplées.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-168">Metacommands are part of the Direct3D 12 API, although they're loosely coupled to it.</span></span> <span data-ttu-id="ccf6c-169">Une interface de commande est identifiée par un [**GUID**](/windows/win32/api/guiddef/ns-guiddef-guid)fixe, alors que presque tout le reste sur celle-ci (de son comportement et sa sémantique à sa signature et son nom) ne fait pas strictement partie de l’API Direct3D 12.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-169">A metacommand is identified by a fixed [**GUID**](/windows/win32/api/guiddef/ns-guiddef-guid), while almost everything else about it (from its behavior and semantics to its signature and name) are not strictly part of the Direct3D 12 API.</span></span> <span data-ttu-id="ccf6c-170">Au lieu de cela, une commande est spécifiée entre son auteur et le pilote qui l’implémente.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-170">Rather, a metacommand is specified between its author and the driver that implements it.</span></span> <span data-ttu-id="ccf6c-171">Dans ce cas, l’auteur est DirectML.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-171">In this case, the author is DirectML.</span></span> <span data-ttu-id="ccf6c-172">Les « recommandes » sont des primitives Direct3D 12 (comme les dessins et les envois). elles peuvent donc être enregistrées dans une liste de commandes et planifiées pour être exécutées ensemble.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-172">Metacommands are Direct3D 12 primitives (just like Draws and Dispatches), so they can be recorded into a command list and scheduled for execution together.</span></span>

<span data-ttu-id="ccf6c-173">DirectML accélère vos charges de travail Machine Learning à l’aide d’une suite complète de recommandes Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-173">DirectML accelerates your machine learning workloads using an entire suite of machine learning metacommands.</span></span> <span data-ttu-id="ccf6c-174">Par conséquent, vous n’avez pas besoin d’écrire des chemins de code spécifiques au fournisseur pour obtenir une accélération matérielle pour votre inférence.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-174">Consequently, you don't need to write vendor-specific code paths to achieve hardware acceleration for your inferencing.</span></span> <span data-ttu-id="ccf6c-175">Si vous exécutez sur une puce d’intelligence artificielle, DirectML utilise ce matériel pour accélérer de manière considérable les opérations telles que la convolution.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-175">If you happen to run on an AI-accelerated chip, then DirectML uses that hardware to greatly accelerate operations such as convolution.</span></span> <span data-ttu-id="ccf6c-176">Vous pouvez utiliser le même code que vous avez écrit, sans le modifier, l’exécuter sur une puce qui n’est pas encore accélérée (par exemple, le GPU intégré de votre ordinateur portable), tout en continuant à bénéficier d’une grande accélération matérielle GPU.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-176">You can take the same code that you wrote, without modifying it, run it on a chip that's not AI-accelerated (perhaps the integrated GPU in your laptop), and still get great GPU hardware acceleration.</span></span> <span data-ttu-id="ccf6c-177">Et si aucun GPU n’est disponible, DirectML revient au processeur.</span><span class="sxs-lookup"><span data-stu-id="ccf6c-177">And if no GPU is available, then DirectML falls back to the CPU.</span></span>
