---
title: Extensibilité
description: Extensibilité
ms.assetid: 39327621-b536-4494-9319-9e9d4f534123
keywords:
- Extensibilité
- RPC appel de procédure distante, meilleures pratiques, évolutivité
ms.topic: article
ms.date: 05/31/2018
ms.openlocfilehash: 0728e35d9c9b27494014363c448be9965e39eea7
ms.sourcegitcommit: 2d531328b6ed82d4ad971a45a5131b430c5866f7
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 09/16/2019
ms.locfileid: "103840621"
---
# <a name="scalability"></a><span data-ttu-id="67704-105">Extensibilité</span><span class="sxs-lookup"><span data-stu-id="67704-105">Scalability</span></span>

<span data-ttu-id="67704-106">Le terme, scalabilité, est souvent utilisé de façon inutilisée.</span><span class="sxs-lookup"><span data-stu-id="67704-106">The term, scalability, is often misused.</span></span> <span data-ttu-id="67704-107">Pour cette section, une double définition est fournie :</span><span class="sxs-lookup"><span data-stu-id="67704-107">For this section, a dual definition is provided:</span></span>

-   <span data-ttu-id="67704-108">L’évolutivité est la possibilité d’utiliser pleinement la puissance de traitement disponible sur un système multiprocesseur (2, 4, 8, 32 ou plus).</span><span class="sxs-lookup"><span data-stu-id="67704-108">Scalability is the ability to fully utilize available processing power on a multiprocessor system (2, 4, 8, 32, or more processors).</span></span>
-   <span data-ttu-id="67704-109">L’évolutivité est la possibilité de traiter un grand nombre de clients.</span><span class="sxs-lookup"><span data-stu-id="67704-109">Scalability is the ability to service a large number of clients.</span></span>

<span data-ttu-id="67704-110">Ces deux définitions associées sont communément appelées *mise à l’échelle*.</span><span class="sxs-lookup"><span data-stu-id="67704-110">These two related definitions are commonly referred to as *scaling up*.</span></span> <span data-ttu-id="67704-111">La fin de cette rubrique fournit des conseils sur la *montée* en charge.</span><span class="sxs-lookup"><span data-stu-id="67704-111">The end of this topic provides tips about *scaling out*.</span></span>

<span data-ttu-id="67704-112">Cette discussion porte exclusivement sur l’écriture de serveurs évolutifs, et non sur des clients évolutifs, car les serveurs évolutifs sont des exigences plus courantes.</span><span class="sxs-lookup"><span data-stu-id="67704-112">This discussion focuses exclusively on writing scalable servers, not scalable clients, because scalable servers are more common requirements.</span></span> <span data-ttu-id="67704-113">Cette section traite également de l’évolutivité dans le contexte des serveurs RPC et RPC uniquement.</span><span class="sxs-lookup"><span data-stu-id="67704-113">This section also addresses scalability in the context of RPC and RPC servers only.</span></span> <span data-ttu-id="67704-114">Les meilleures pratiques en matière d’évolutivité, telles que la réduction de la contention, l’évitement des échecs fréquents de cache sur les emplacements de mémoire globaux ou l’évitement de faux partage, ne sont pas abordées ici.</span><span class="sxs-lookup"><span data-stu-id="67704-114">Best practices for scalability, such as reducing contention, avoiding frequent cache misses on global memory locations, or avoiding false sharing, are not discussed here.</span></span>

## <a name="rpc-threading-model"></a><span data-ttu-id="67704-115">Modèle de thread RPC</span><span class="sxs-lookup"><span data-stu-id="67704-115">RPC Threading Model</span></span>

<span data-ttu-id="67704-116">Lors de la réception d’un appel RPC par un serveur, la routine de serveur (routine de gestionnaire) est appelée sur un thread fourni par RPC.</span><span class="sxs-lookup"><span data-stu-id="67704-116">When an RPC call is received by a server, the server routine (manager routine) is called on a thread supplied by RPC.</span></span> <span data-ttu-id="67704-117">RPC utilise un pool de threads adaptatif qui augmente et diminue à mesure que la charge de travail fluctue.</span><span class="sxs-lookup"><span data-stu-id="67704-117">RPC uses an adaptive thread pool that increases and decreases as workload fluctuates.</span></span> <span data-ttu-id="67704-118">À compter de Windows 2000, le cœur du pool de threads RPC est un port de terminaison.</span><span class="sxs-lookup"><span data-stu-id="67704-118">Starting with Windows 2000, the core of the RPC thread pool is a completion port.</span></span> <span data-ttu-id="67704-119">Le port de terminaison et son utilisation par RPC sont réglés pour les routines de serveur de contention de zéro à faible.</span><span class="sxs-lookup"><span data-stu-id="67704-119">The completion port and its usage by RPC are tuned for zero to low contention server routines.</span></span> <span data-ttu-id="67704-120">Cela signifie que le pool de threads RPC augmente agressivement le nombre de threads de maintenance si certains sont bloqués.</span><span class="sxs-lookup"><span data-stu-id="67704-120">This means that the RPC thread pool aggressively increases the number of servicing threads if some become blocked.</span></span> <span data-ttu-id="67704-121">Il s’agit du présomption que le blocage est rare, et si un thread est bloqué, il s’agit d’une condition temporaire qui est rapidement résolue.</span><span class="sxs-lookup"><span data-stu-id="67704-121">It operates on the presumption that blocking is rare, and if a thread gets blocked, this is a temporary condition that is quickly resolved.</span></span> <span data-ttu-id="67704-122">Cette approche permet d’obtenir de l’efficacité pour les serveurs de contention insuffisants.</span><span class="sxs-lookup"><span data-stu-id="67704-122">This approach enables efficiency for low contention servers.</span></span> <span data-ttu-id="67704-123">Par exemple, un serveur RPC appel void fonctionnant sur un serveur 550MHz à huit processeurs accessible via un réseau SAN à haut débit occupe plus de 30 000 appels void par seconde à partir de plus de 200 clients distants.</span><span class="sxs-lookup"><span data-stu-id="67704-123">For example, a void call RPC server operating on an eight-processor 550MHz server accessed over a high speed system area network (SAN) serves over 30,000 void calls per second from over 200 remote clients.</span></span> <span data-ttu-id="67704-124">Cela représente plus de 108 millions appels par heure.</span><span class="sxs-lookup"><span data-stu-id="67704-124">This represents more than 108 million calls per hour.</span></span>

<span data-ttu-id="67704-125">Le résultat est que le pool de threads agressif est réellement utilisé lorsque la contention sur le serveur est élevée.</span><span class="sxs-lookup"><span data-stu-id="67704-125">The result is that the aggressive thread pool actually gets in the way when contention on the server is high.</span></span> <span data-ttu-id="67704-126">À titre d’illustration, imaginez un serveur lourd utilisé pour accéder à distance à des fichiers.</span><span class="sxs-lookup"><span data-stu-id="67704-126">To illustrate, imagine a heavy-duty server used to remotely access files.</span></span> <span data-ttu-id="67704-127">Supposons que le serveur adopte l’approche la plus simple : il lit simplement/écrit le fichier de façon synchrone sur le thread sur lequel le RPC appelle la routine du serveur.</span><span class="sxs-lookup"><span data-stu-id="67704-127">Assume the server adopts the most straightforward approach: it simply reads/writes the file synchronously on the thread on which that RPC invokes the server routine.</span></span> <span data-ttu-id="67704-128">Par ailleurs, supposons que nous disposons d’un serveur à quatre processeurs desservant de nombreux clients.</span><span class="sxs-lookup"><span data-stu-id="67704-128">Also, assume we have a four-processor server serving many clients.</span></span>

<span data-ttu-id="67704-129">Le serveur démarre avec cinq threads (cela varie en réalité, mais cinq threads sont utilisés pour des raisons de simplicité).</span><span class="sxs-lookup"><span data-stu-id="67704-129">The server will start with five threads (this actually varies, but five threads is used for simplicity).</span></span> <span data-ttu-id="67704-130">Une fois que RPC sélectionne le premier appel RPC, il distribue l’appel à la routine du serveur et la routine du serveur émet les e/s.</span><span class="sxs-lookup"><span data-stu-id="67704-130">Once RPC picks up the first RPC call, it dispatches the call to the server routine, and the server routine issues the I/O.</span></span> <span data-ttu-id="67704-131">Rarement, il manque le cache de fichiers, puis bloque l’attente du résultat.</span><span class="sxs-lookup"><span data-stu-id="67704-131">Infrequently, it misses the file cache and then blocks waiting for the result.</span></span> <span data-ttu-id="67704-132">Dès qu’il se bloque, le cinquième thread est libéré pour récupérer une demande, et un sixième thread est créé en tant que secours à chaud.</span><span class="sxs-lookup"><span data-stu-id="67704-132">As soon as it blocks, the fifth thread is released to pick up a request, and a sixth thread is created as a hot standby.</span></span> <span data-ttu-id="67704-133">En supposant que chaque dixième opération d’e/s n’a pas atteint le cache et se bloque pendant 100 millisecondes (une valeur temporelle arbitraire), et en supposant que le serveur à quatre processeurs fait environ 20 000 appels par seconde (5 000 appels par processeur), une modélisation simpliste prédirea que chaque processeur générera environ 50 threads.</span><span class="sxs-lookup"><span data-stu-id="67704-133">Assuming each tenth I/O operation misses the cache and will block for 100 milliseconds (an arbitrary time value), and assuming the four-processor server serves about 20,000 calls per second (5,000 calls per processor), a simplistic modeling would predict that each processor will spawn approximately 50 threads.</span></span> <span data-ttu-id="67704-134">Cela suppose un appel qui se bloquera toutes les 2 millisecondes, et après 100 millisecondes, le premier thread est libéré à nouveau afin que le pool se stabilise à environ 200 threads (50 par processeur).</span><span class="sxs-lookup"><span data-stu-id="67704-134">This assumes a call that will block comes every 2 milliseconds, and after 100 milliseconds the first thread is freed again so the pool will stabilize at about 200 threads (50 per processor).</span></span>

<span data-ttu-id="67704-135">Le comportement réel est plus compliqué, car le nombre élevé de threads entraîne des changements de contexte supplémentaires qui ralentissent le serveur et ralentissent également le taux de création de nouveaux threads, mais l’idée de base est claire.</span><span class="sxs-lookup"><span data-stu-id="67704-135">The actual behavior is more complicated, as the high number of threads will cause extra context switches which slow the server, and also slow the rate of creation of new threads, but the basic idea is clear.</span></span> <span data-ttu-id="67704-136">Le nombre de threads s’affiche rapidement à mesure que les threads sur le serveur commencent à se bloquer et attendent un événement (qu’il s’agit d’une e/s ou d’un accès à une ressource).</span><span class="sxs-lookup"><span data-stu-id="67704-136">The number of threads goes up quickly as threads on the server start blocking and waiting for something (be it an I/O, or access to a resource).</span></span>

<span data-ttu-id="67704-137">RPC et le port de terminaison qui permet aux demandes entrantes de gérer le nombre de threads RPC utilisables dans le serveur sont égaux au nombre de processeurs sur l’ordinateur.</span><span class="sxs-lookup"><span data-stu-id="67704-137">RPC and the completion port that gates incoming requests will try to maintain the number of usable RPC threads in the server to be equal to the number of processors on the machine.</span></span> <span data-ttu-id="67704-138">Cela signifie que sur un serveur à quatre processeurs, une fois qu’un thread revient à RPC, s’il y a quatre threads RPC ou plus utilisables, le cinquième thread n’est pas autorisé à récupérer une nouvelle requête, mais il se trouve à la place dans un état de secours dans le cas où l’un des threads actuellement utilisables est bloqué.</span><span class="sxs-lookup"><span data-stu-id="67704-138">This means that on a four-processor server, once a thread returns to RPC, if there are four or more usable RPC threads, the fifth thread is not allowed to pick up a new request, and instead will sit in a hot standby state in case one of the currently usable threads blocks.</span></span> <span data-ttu-id="67704-139">Si le cinquième thread attend suffisamment longtemps comme un secours sans que le nombre de threads RPC utilisants ne se libère sous le nombre de processeurs, il est libéré, autrement dit, le pool de threads diminue.</span><span class="sxs-lookup"><span data-stu-id="67704-139">If the fifth thread waits long enough as a hot standby without the number of usable RPC threads dropping below the number of processors, it will be released, that is, the thread pool will decrease.</span></span>

<span data-ttu-id="67704-140">Imaginez un serveur avec de nombreux threads.</span><span class="sxs-lookup"><span data-stu-id="67704-140">Imagine a server with many threads.</span></span> <span data-ttu-id="67704-141">Comme expliqué précédemment, un serveur RPC finit avec un grand nombre de threads, mais uniquement si les threads se bloquent souvent.</span><span class="sxs-lookup"><span data-stu-id="67704-141">As previously explained, an RPC server ends up with many threads, but only if the threads block often.</span></span> <span data-ttu-id="67704-142">Sur un serveur où les threads se bloquent souvent, un thread qui retourne à RPC est bientôt retiré de la liste de secours, car tous les threads actuellement utilisables sont bloqués et reçoivent une demande de traitement.</span><span class="sxs-lookup"><span data-stu-id="67704-142">On a server where threads often block, a thread that returns to RPC is soon taken out of the hot standby list, because all currently usable threads block, and is given a request to process.</span></span> <span data-ttu-id="67704-143">Lorsqu’un thread se bloque, le répartiteur de threads dans le noyau bascule le contexte vers un autre thread.</span><span class="sxs-lookup"><span data-stu-id="67704-143">When a thread blocks, the thread dispatcher in the kernel switches context to another thread.</span></span> <span data-ttu-id="67704-144">Ce changement de contexte lui-même consomme des cycles d’UC.</span><span class="sxs-lookup"><span data-stu-id="67704-144">This context switch by itself consumes CPU cycles.</span></span> <span data-ttu-id="67704-145">Le thread suivant va exécuter un code différent, accéder à différentes structures de données et aura une pile différente, ce qui signifie que le taux d’accès au cache mémoire (caches L1 et L2) sera beaucoup plus faible, ce qui ralentit l’exécution.</span><span class="sxs-lookup"><span data-stu-id="67704-145">The next thread will be executing different code, accessing different data structures, and will have a different stack, which means the memory cache hit rate (the L1 and L2 caches) will be much lower, resulting in slower execution.</span></span> <span data-ttu-id="67704-146">Les nombreux threads qui s’exécutent simultanément augmentent la contention des ressources existantes, telles que le segment de mémoire, les sections critiques dans le code serveur, et ainsi de suite.</span><span class="sxs-lookup"><span data-stu-id="67704-146">The numerous threads executing simultaneously increases contention for existing resources, such as heap, critical sections in the server code, and so on.</span></span> <span data-ttu-id="67704-147">Cela augmente davantage la contention en tant que convois sur les ressources.</span><span class="sxs-lookup"><span data-stu-id="67704-147">This further increases contention as convoys on resources form.</span></span> <span data-ttu-id="67704-148">Si la mémoire est faible, la sollicitation de la mémoire exercée par le nombre important et croissant de threads provoquera des défauts de page, ce qui augmentera encore la vitesse à laquelle les threads se bloquent et entraînera la création d’un plus grand nombre de threads.</span><span class="sxs-lookup"><span data-stu-id="67704-148">If memory is low, the memory pressure exerted by the large and growing number of threads will cause page faults, which further increase the rate at which the threads block, and cause even more threads to be created.</span></span> <span data-ttu-id="67704-149">En fonction de la fréquence de blocage et de la quantité de mémoire physique disponible, le serveur peut se stabiliser à un niveau de performance inférieur avec un taux de changement de contexte élevé, ou se détériorer jusqu’au point où il accède uniquement au disque dur et au basculement de contexte sans effectuer de travail réel.</span><span class="sxs-lookup"><span data-stu-id="67704-149">Depending on how often it blocks and how much physical memory is available, the server may either stabilize at some lower level of performance with a high context switch rate, or it may deteriorate to the point where it is only repeatedly accessing the hard disk and context switching without performing any actual work.</span></span> <span data-ttu-id="67704-150">Cette situation ne s’affiche pas sous la charge de travail légère, bien entendu, mais une charge de travail lourde pose rapidement le problème à la surface.</span><span class="sxs-lookup"><span data-stu-id="67704-150">This situation will not show under light workload, of course, but a heavy workload quickly brings the problem to the surface.</span></span>

<span data-ttu-id="67704-151">Comment cela peut-il être évité ?</span><span class="sxs-lookup"><span data-stu-id="67704-151">How can this be prevented?</span></span> <span data-ttu-id="67704-152">Si les threads sont censés être bloqués, déclarez les appels comme asynchrones, et une fois que la demande entre dans la routine du serveur, faites-la mettre en file d’attente vers un pool de threads de travail qui utilisent les fonctionnalités asynchrones du système d’e/s et/ou RPC.</span><span class="sxs-lookup"><span data-stu-id="67704-152">If threads are expected to block, declare calls as asynchronous, and once the request enters the server routine, queue it to a pool of worker threads that use the asynchronous capabilities of the I/O system and/or RPC.</span></span> <span data-ttu-id="67704-153">Si le serveur est à son tour, les appels RPC deviennent asynchrones et s’assurent que la file d’attente ne devient pas trop volumineuse.</span><span class="sxs-lookup"><span data-stu-id="67704-153">If the server is in turn making RPC calls make those asynchronous, and make sure the queue does not grow too large.</span></span> <span data-ttu-id="67704-154">Si la routine de serveur effectue des e/s de fichier, utilisez des e/s de fichier asynchrones pour mettre en file d’attente plusieurs demandes dans le système d’e/s et n’avoir que quelques threads en file d’attente et récupérer les résultats.</span><span class="sxs-lookup"><span data-stu-id="67704-154">If the server routine is performing file I/O, use asynchronous file I/O to queue multiple requests to the I/O system and have only a few threads queue them and pick up the results.</span></span> <span data-ttu-id="67704-155">Si la routine de serveur fait des e/s réseau, utilisez de nouveau les fonctionnalités asynchrones du système pour émettre les requêtes et récupérer les réponses de façon asynchrone et utilisez le moins de threads possible.</span><span class="sxs-lookup"><span data-stu-id="67704-155">If the server routine is doing network I/O, again, use the asynchronous capabilities of the system to issue the requests and pick up the replies asynchronously, and use as few threads as possible.</span></span> <span data-ttu-id="67704-156">Une fois que l’e/s est terminée ou que l’appel RPC effectué par le serveur est terminé, terminez l’appel RPC asynchrone qui a fourni la demande.</span><span class="sxs-lookup"><span data-stu-id="67704-156">When the I/O is done, or the RPC call the server made is complete, complete the asynchronous RPC call that delivered the request.</span></span> <span data-ttu-id="67704-157">Cela permet au serveur de s’exécuter avec le moins de threads possible, ce qui augmente les performances et le nombre de clients qu’un serveur peut traiter.</span><span class="sxs-lookup"><span data-stu-id="67704-157">This will enable the server to run with as few threads as possible, which increases the performance and the number of clients a server can service.</span></span>

## <a name="scale-out"></a><span data-ttu-id="67704-158">Scale Out</span><span class="sxs-lookup"><span data-stu-id="67704-158">Scale Out</span></span>

<span data-ttu-id="67704-159">RPC peut être configuré pour fonctionner avec l’équilibrage de la charge réseau (NLB) si NLB est configuré de telle sorte que toutes les demandes d’une adresse de client donnée sont dirigées vers le même serveur.</span><span class="sxs-lookup"><span data-stu-id="67704-159">RPC can be configured to work with Network Load Balancing (NLB) if NLB is configured such that all requests from a given client address go to the same server.</span></span> <span data-ttu-id="67704-160">Étant donné que chaque client RPC ouvre un pool de connexions (pour plus d’informations, voir [RPC et le réseau](rpc-and-the-network.md)), il est essentiel que toutes les connexions à partir du pool du client donné finissent sur le même ordinateur serveur.</span><span class="sxs-lookup"><span data-stu-id="67704-160">Because each RPC client opens a connection pool (for more information, see [RPC and the Network](rpc-and-the-network.md)), it is essential that all connections from the pool of the given client end up on the same server computer.</span></span> <span data-ttu-id="67704-161">Tant que cette condition est remplie, un cluster d’équilibrage de la charge réseau peut être configuré pour fonctionner comme un serveur RPC volumineux avec une évolutivité potentiellement excellente.</span><span class="sxs-lookup"><span data-stu-id="67704-161">As long as this condition is met, an NLB cluster can be configured to function as one large RPC server with potentially excellent scalability.</span></span>

 

 




